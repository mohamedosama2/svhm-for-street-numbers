{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\dclap\\pycharmprojects\\emotion_recognition\\venv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x={}\n",
    "\n",
    "mat = scipy.io.loadmat('data/extra_32x32.mat')\n",
    "for i in range(0,500000):\n",
    "    x[i]=mat['X'][:,:,:,i].reshape(32,32,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "for i in range(1,200000):\n",
    "    if mat['y'][i]==10:\n",
    "        mat['y'][i]=0    \n",
    "        \n",
    "y={}\n",
    "for i in range(0,200000):\n",
    "    y[i]=mat['y'][i]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.zeros(shape=(200000,32,32,3))\n",
    "for i in range(0,200000):\n",
    "    X[i]=np.array(x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.zeros(shape=(200000))\n",
    "for i in range(0,200000):\n",
    "    Y[i]=np.array(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.7, wspace=0.7)\n",
    "for i in range (1,7):\n",
    "    ax = fig.add_subplot(2, 3, i)\n",
    "    plt.imshow(X[i].reshape(32,32,3))\n",
    "    plt.title(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x , y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "\n",
    "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "\n",
    "    return gray\n",
    "\n",
    "x_train1=np.zeros(shape=(150000,32,32))\n",
    "for i in range (0,150000):\n",
    "    x_train1[i]=rgb2gray(x_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test1=np.zeros(shape=(50000,32,32))\n",
    "for i in range (0,50000):\n",
    "    x_test1[i]=rgb2gray(x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test1=x_test1.reshape(50000,32,32,1)\n",
    "x_train1=x_train1.reshape(150000,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train/255\n",
    "x_test=x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test=to_categorical(y_test,num_classes=10)\n",
    "y_train=to_categorical(y_train,num_classes=10)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DCLAP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DCLAP\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 30)        780       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 15)        4065      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 15)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6, 6, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 540)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               69248     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 81,053\n",
      "Trainable params: 81,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#the model\n",
    "model=Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(32,32,1), activation='relu',))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    " \n",
    "#2rd convolution layer\n",
    "model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "#flatten\n",
    "model.add(Flatten())\n",
    "#layer 1\n",
    "model.add(Dense(128,activation='relu')) \n",
    "#layer 2\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=10,min_delta=0.0001)\n",
    "mc=ModelCheckpoint('best_model21.hdf5',monitor='val_acc',verbose=1,save_best_only=True,mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DCLAP\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 150000 samples, validate on 50000 samples\n",
      "Epoch 1/10\n",
      "150000/150000 [==============================] - 1111s 7ms/step - loss: 1.2142 - acc: 0.6590 - val_loss: 0.4074 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.88252, saving model to best_model21.hdf5\n",
      "Epoch 2/10\n",
      "150000/150000 [==============================] - 371s 2ms/step - loss: 0.4332 - acc: 0.8703 - val_loss: 0.2893 - val_acc: 0.9176\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.88252 to 0.91758, saving model to best_model21.hdf5\n",
      "Epoch 3/10\n",
      "150000/150000 [==============================] - 373s 2ms/step - loss: 0.3472 - acc: 0.8981 - val_loss: 0.2386 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91758 to 0.93358, saving model to best_model21.hdf5\n",
      "Epoch 4/10\n",
      "150000/150000 [==============================] - 402s 3ms/step - loss: 0.2987 - acc: 0.9118 - val_loss: 0.2249 - val_acc: 0.9365\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93358 to 0.93654, saving model to best_model21.hdf5\n",
      "Epoch 5/10\n",
      "150000/150000 [==============================] - 373s 2ms/step - loss: 0.2709 - acc: 0.9203 - val_loss: 0.2409 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93654\n",
      "Epoch 6/10\n",
      "150000/150000 [==============================] - 419s 3ms/step - loss: 0.2482 - acc: 0.9268 - val_loss: 0.1851 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.93654 to 0.94886, saving model to best_model21.hdf5\n",
      "Epoch 7/10\n",
      "150000/150000 [==============================] - 392s 3ms/step - loss: 0.2306 - acc: 0.9320 - val_loss: 0.1772 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.94886 to 0.95122, saving model to best_model21.hdf5\n",
      "Epoch 8/10\n",
      "150000/150000 [==============================] - 275s 2ms/step - loss: 0.2176 - acc: 0.9359 - val_loss: 0.1685 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.95122 to 0.95414, saving model to best_model21.hdf5\n",
      "Epoch 9/10\n",
      "150000/150000 [==============================] - 274s 2ms/step - loss: 0.1999 - acc: 0.9408 - val_loss: 0.1614 - val_acc: 0.9568\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.95414 to 0.95676, saving model to best_model21.hdf5\n",
      "Epoch 10/10\n",
      "150000/150000 [==============================] - 278s 2ms/step - loss: 0.1920 - acc: 0.9431 - val_loss: 0.1676 - val_acc: 0.9550\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.95676\n"
     ]
    }
   ],
   "source": [
    "#fitting the data\n",
    "history=model.fit(x_train1, y_train, validation_data=(x_test1, y_test),callbacks=[es,mc], epochs=10, batch_size=200,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.16756379462584853\n",
      "Test accuracy: 0.95504\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(x_test1, y_test, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
